{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba29c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transformtransforms\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 50\n",
    "WORKERS = 0\n",
    "\n",
    "RANDOM_SEED = 2099\n",
    "\n",
    "IMG_SIZE = 64\n",
    "LEARNING_RATE = 0.0002\n",
    "NOISE_DIM = 100\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "TORCH_CUDA_ARCH_LIST = \"8.6\"\n",
    "\n",
    "print('torch.version: ', torch.__version__)\n",
    "print('torch.version.cuda: ', torch.version.cuda)\n",
    "print('torch.cuda.is_available: ', torch.cuda.is_available())\n",
    "print('torch.cuda.device_count: ', torch.cuda.device_count())\n",
    "current_device = torch.cuda.current_device()\n",
    "torch.cuda.device(current_device)\n",
    "print('torch.cuda.get_device_name: ', torch.cuda.get_device_name(current_device))\n",
    "compute_device = torch.device(\"cuda\")\n",
    "\n",
    "transform_pipeline = transforms.Compose([transforms.Resize(IMG_SIZE),\n",
    "                                         transforms.CenterCrop(IMG_SIZE),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                              (0.5, 0.5, 0.5)),])\n",
    "\n",
    "data_set = torchvision.datasets.CIFAR10(root=\"./data/\", \n",
    "                                        download=True,\n",
    "                                        transform=transform_pipeline)\n",
    "\n",
    "data_loader = DataLoader(data_set, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, \n",
    "                         num_workers=WORKERS)\n",
    "\n",
    "print(data_set.classes)\n",
    "print(data_set.data.shape)\n",
    "\n",
    "class ImageGenerator(nn.Module):\n",
    "    def __init__(self, input_noise=NOISE_DIM):\n",
    "        super(ImageGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_noise, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def init_weights(self, mean_w=0, std_w=0.02, mean_b=1, std_b=0.02):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.normal_(module.weight.data, mean_w, std_w)\n",
    "                nn.init.constant_(module.bias.data, 0)\n",
    "\n",
    "generator = ImageGenerator().to(compute_device)\n",
    "summary(generator, input_size=(100, 1, 1))\n",
    "\n",
    "class ImageDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def init_weights(self, mean_w=0, std_w=0.02, mean_b=1, std_b=0.02):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.normal_(module.weight.data, mean_w, std_w)\n",
    "                nn.init.constant_(module.bias.data, 0)\n",
    "\n",
    "discriminator = ImageDiscriminator().to(compute_device)\n",
    "summary(discriminator, input_size=(3, 64, 64))\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optim_gen = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optim_disc = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "noise_input = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1)\n",
    "noise_input = noise_input.to(compute_device)\n",
    "\n",
    "real_mark = 1.0\n",
    "fake_mark = 0.0\n",
    "\n",
    "print('start training...')\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, batch_data in enumerate(data_loader):\n",
    "        discriminator.zero_grad()\n",
    "        real_images = batch_data[0].to(compute_device)\n",
    "        real_labels = torch.full((BATCH_SIZE, 1, 1, 1), real_mark, device=compute_device)\n",
    "        real_output = discriminator(real_images)\n",
    "        loss_real = loss_function(real_output, real_labels)\n",
    "        loss_real.backward()\n",
    "        real_score = real_output.mean().item()\n",
    "\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1, device=compute_device)\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = torch.full((BATCH_SIZE, 1, 1, 1), fake_mark, device=compute_device)\n",
    "        fake_output = discriminator(fake_images.detach())\n",
    "        loss_fake = loss_function(fake_output, fake_labels)\n",
    "        loss_fake.backward()\n",
    "        fake_score = fake_output.mean().item()\n",
    "        disc_loss = loss_real + loss_fake\n",
    "        optim_disc.step()\n",
    "\n",
    "        generator.zero_grad()\n",
    "        fake_labels.fill_(real_mark)\n",
    "        fake_output = discriminator(fake_images)\n",
    "        gen_loss = loss_function(fake_output, fake_labels)\n",
    "        gen_loss.backward()\n",
    "        optim_gen.step()\n",
    "\n",
    "        if i % (len(data_loader)//50) == 0:\n",
    "            discriminator.eval()\n",
    "            generator.eval()\n",
    "            noise = torch.randn(10, NOISE_DIM, 1, 1, device=compute_device)\n",
    "            test_images = generator(noise)\n",
    "            test_images_grid = create_image_grid(test_images)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(test_images_grid)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Epoch: {epoch} Iteration: {i}', fontsize=16)\n",
    "            plt.show()\n",
    "            print(f'[{epoch}/{NUM_EPOCHS}][{i}/{len(data_loader)}] Loss_D: {disc_loss:.4f} Loss_G: {gen_loss:.4f} D(x): {real_score:.4f} D(G(z)): {fake_score:.4f}')\n",
    "            discriminator.train()\n",
    "            generator.train()\n",
    "\n",
    "end_time = time.time()\n",
    "print('Done! Total time cost: ', end_time - start_time)\n",
    "\n",
    "def test_generator(num_images=10):\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "    top_images = []\n",
    "    index = 0\n",
    "    while index < num_images:\n",
    "        test_noise = torch.randn(1, NOISE_DIM, 1, 1, device=compute_device)\n",
    "        test_image = generator(test_noise)\n",
    "        image_score = discriminator(test_image).detach().cpu().numpy()[0][0][0][0]\n",
    "        if image_score > 0.9:\n",
    "            print(image_score)\n",
    "            formatted_image = test_image.detach().permute(0, 2, 3, 1).cpu().numpy()[0]\n",
    "            top_images.append(normalize_image(formatted_image))\n",
    "            index += 1\n",
    "    return top_images\n",
    "\n",
    "top_test_images = test_generator(10)\n",
    "\n",
    "def display_images(images):\n",
    "    n = len(images)\n",
    "    col = 5\n",
    "    row = n // col\n",
    "    combined_images = np.array([])\n",
    "    for i in range(row):\n",
    "        row_images = np.array([])\n",
    "        for j in range(col):\n",
    "            image = images[i * col + j]\n",
    "            if j == 0:\n",
    "                row_images = image\n",
    "            else:\n",
    "                row_images = np.hstack((row_images, image))\n",
    "        if i == 0:\n",
    "            combined_images = row_images\n",
    "        else:\n",
    "            combined_images = np.vstack((combined_images, row_images))\n",
    "    return combined_images\n",
    "\n",
    "final_image_display = display_images(top_test_images)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(final_image_display)\n",
    "plt.axis('off')\n",
    "plt.title(f'DCGAN Epochs:{NUM_EPOCHS} Batch:{BATCH_SIZE} D/G: 1/1', fontsize=20)\n",
    "plt.savefig('DCGAN_image_wall_plot.png')\n",
    "plt.show()\n",
    "\n",
    "cv2.imwrite('DCGAN_image_wall.png', cv2.cvtColor(final_image_display, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5c229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
